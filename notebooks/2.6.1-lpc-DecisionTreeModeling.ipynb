{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Modelling\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
    "#%pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import (train_test_split, GridSearchCV)\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#basic tools \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "#tuning hyperparameters\n",
    "from bayes_opt import BayesianOptimization\n",
    "from skopt  import BayesSearchCV \n",
    "#%pip install hgboost\n",
    "from hgboost import hgboost\n",
    "from hyperopt import hp\n",
    "from skopt import gp_minimize\n",
    "\n",
    "# Visualisation\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Src modules -- Update the * to get only what I need\n",
    "sys.path.append(os.path.dirname(os.getcwd())) # Add the parent directory to the Python path so we can import src modules\n",
    "from src.data_setup import *\n",
    "from src.decision_tree import *\n",
    "from src.model_evaluation import model_eval_pipeline,calc_root_mean_squared_error,calc_root_mean_squared_log_error,rmsle_func,rmsle_lgbm\n",
    "from src.visualisation import *\n",
    "from src.model_utils import *\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train,val and test data\n",
    "#train, test, stores, transactions = get_data()\n",
    "\n",
    "#data = get_oil_holiday_data()\n",
    "#df_data=Transform_Data_For_DT(data,60,True)\n",
    "#df_data_feats=DT_features(df_data,False)\n",
    "#df_data.to_pickle(DATA_PATH/'processed/DT.pkl')\n",
    "#df_data_feats.to_pickle(DATA_PATH/'processed/DT_Features.pkl')\n",
    "#data.to_pickle(DATA_PATH/'processed/Data.pkl')\n",
    "\n",
    "df_data=pickle.load(open(DATA_PATH/'processed/DT.pkl','rb'))\n",
    "df_data_feats=pickle.load(open(DATA_PATH/'processed/DT_Features.pkl','rb'))\n",
    "data=pickle.load(open(DATA_PATH/'processed/Data.pkl','rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create main dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data['is_test']==False]\n",
    "train=train.drop(columns={'is_test'})\n",
    "test = data[data['is_test']==True]\n",
    "test=test.drop(columns={'is_test'})\n",
    "\n",
    "df_data_feats = df_data_feats.astype({'target': 'float'})\n",
    "df_feats = df_data_feats[df_data_feats['is_test']==False]\n",
    "df_train = df_data[df_data['is_test']==False]\n",
    "df_test_feats = df_data_feats[df_data_feats['is_test']==True]\n",
    "df_test = df_data[df_data['is_test']==True]\n",
    "df_feats=df_feats.drop(columns={'is_test'})\n",
    "df_train=df_train.drop(columns={'is_test'})\n",
    "df_test=df_test.drop(columns={'is_test'})\n",
    "df_test_feats=df_test_feats.drop(columns={'is_test'})\n",
    "cat_list=['family','city','state','type']\n",
    "df_le=pd.DataFrame()\n",
    "for x in cat_list:\n",
    "    list =train[x].unique()\n",
    "    x_le = pd.DataFrame(list, columns=[x])\n",
    "    le=LabelEncoder()\n",
    "    x_le[x+'_le']=le.fit_transform(x_le[x])\n",
    "    df_le=df_le.append(x_le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Create Train and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['date']= pd.to_datetime(df_train['date'])\n",
    "df_feats['date']= pd.to_datetime(df_feats['date'])\n",
    "try:\n",
    "    df_train=df_train.drop(columns={'Unnamed: 0'})\n",
    "except: \n",
    "    df_train=df_train\n",
    "try: \n",
    "    df_feats=df_feats.drop(columns={'Unnamed: 0'})\n",
    "except:\n",
    "    df_feats=df_feats\n",
    "#Create the split train/validation\n",
    "df_training,df_validation=train_val_split(df_train,2)\n",
    "df_feats_use,df_feats_validation=train_val_split(df_feats,2)\n",
    "\n",
    "#Remove column for features dataframe\n",
    "cols = [col for col in df_feats.columns if col not in ['date', 'id', \"sales\", \"day\",'target']]\n",
    "Y_train = df_feats_use['sales']\n",
    "X_train = df_feats_use[cols]\n",
    "Y_val = df_feats_validation['sales']\n",
    "X_val = df_feats_validation[cols]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_plot = train.set_index('date')\n",
    "y = train_plot['sales'].resample('MS').mean() \n",
    "\n",
    "result = sm.tsa.seasonal_decompose(y, model='additive')\n",
    "fig = plt.figure()  \n",
    "fig = result.plot()  \n",
    "fig.set_size_inches(8, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_interactive_treemap(train,10, [ 'month', 'family','store_nbr'],'sales','sales',3,'Blues')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Optimisation - fine tuning hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_evaluation(params):\n",
    "    num_leaves, learning_rate, max_depth, feature_fraction, bagging_fraction, bagging_freq, min_data_in_leaf = params\n",
    "    \n",
    "    model = lgb.LGBMRegressor(\n",
    "        boosting_type='gbdt',\n",
    "        objective='regression',  # Use 'regression' for regression\n",
    "        metric='None',           # We set metric to 'None' since we'll use our custom evaluation function\n",
    "        num_leaves=int(num_leaves),\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=int(max_depth),\n",
    "        feature_fraction=feature_fraction,\n",
    "        bagging_fraction=bagging_fraction,\n",
    "        bagging_freq=int(bagging_freq),\n",
    "        min_data_in_leaf=int(min_data_in_leaf),\n",
    "        verbose=-100\n",
    "    )\n",
    "    params = model.get_params()\n",
    "    aliases = [\n",
    "        {'min_child_weight', 'min_sum_hessian_in_leaf'},\n",
    "        {'min_child_samples', 'min_data_in_leaf'},\n",
    "        {'colsample_bytree', 'feature_fraction'},\n",
    "        {'subsample', 'bagging_fraction'},\n",
    "        {'subsample_freq','bagging_freq'}\n",
    "    ]\n",
    "    for alias in aliases:\n",
    "        if len(alias & set(params)) == 2:\n",
    "            arg = np.random.choice(sorted(alias))\n",
    "            params[arg] = None\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "    model.fit(X_train_temp, Y_train_temp, verbose=False)\n",
    "    y_pred = model.predict(X_val_temp)\n",
    "\n",
    "    # Calculate the RMSLE score\n",
    "    rmsle_score = rmsle_func(Y_val_temp, y_pred)\n",
    "\n",
    "    # Return the RMSLE score\n",
    "    return rmsle_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [\n",
    "    (10, 400),  # num_leaves\n",
    "    (0.01, 0.5),  # learning_rate\n",
    "    (5, 200),  # max_depth\n",
    "    (0.1, 0.9),  # feature_fraction\n",
    "    (0.1, 0.9),  # bagging_fraction\n",
    "    (0, 100),  # bagging_freq\n",
    "    (20, 200)  # min_data_in_leaf\n",
    "]\n",
    "# Perform Bayesian Optimization to find the best hyperparameters\n",
    "result = gp_minimize(lgbm_evaluation, space, n_calls=1000, random_state=42)\n",
    "\n",
    "# Extract the best hyperparameters and their corresponding score\n",
    "best_params = {\n",
    "    'num_leaves': int(result.x[0]),\n",
    "    'learning_rate': result.x[1],\n",
    "    'max_depth': int(result.x[2]),\n",
    "    'feature_fraction': result.x[3],\n",
    "    'bagging_fraction': result.x[4],\n",
    "    'bagging_freq': int(result.x[5]),\n",
    "    'min_data_in_leaf': int(result.x[6])\n",
    "}\n",
    "\n",
    "best_score = result.fun  # Convert back to positive, as gp_minimize works with the negation of the score\n",
    "\n",
    "# Print the best hyperparameters and the corresponding score\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_params)\n",
    "print(\"Best RMSLE Score:\")\n",
    "print(best_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_PARAMS = {}\n",
    "\n",
    "FIXED_PARAMS={'objective': 'regression',\n",
    "              'metric': 'custom',\n",
    "              'boosting':'gbdt',\n",
    "              'min_gain_to_split':0.01,\n",
    "              'num_boost_round':500,\n",
    "              'early_stopping_rounds':50}\n",
    "param = dict(SEARCH_PARAMS,**FIXED_PARAMS)\n",
    "cols_no_fam = [col for col in df_feats.columns if col not in ['date', 'id', \"sales\", \"day\",'target','family']]\n",
    "for fam in df_feats_use['family'].unique():\n",
    "    temp=df_feats_use[df_feats_use['family']==fam]\n",
    "    temp_val=df_feats_validation[df_feats_validation['family']==fam]\n",
    "    Y_train_temp = temp['sales']\n",
    "    X_train_temp = temp[cols_no_fam]\n",
    "    Y_val_temp = temp_val['sales']\n",
    "    X_val_temp = temp_val[cols_no_fam]\n",
    "    space = [\n",
    "        (10, 200),  # num_leaves\n",
    "        (0.01, 0.5),  # learning_rate\n",
    "        (5, 100),  # max_depth\n",
    "        (0.1, 0.9),  # feature_fraction\n",
    "        (0.1, 0.9),  # bagging_fraction\n",
    "        (0, 10),  # bagging_freq\n",
    "        (20, 200)  # min_data_in_leaf\n",
    "    ]\n",
    "    # Perform Bayesian Optimization to find the best hyperparameters\n",
    "    result = gp_minimize(lgbm_evaluation, space, n_calls=100, random_state=42)\n",
    "\n",
    "    # Extract the best hyperparameters and their corresponding score\n",
    "    best_params = {\n",
    "        'num_leaves': int(result.x[0]),\n",
    "        'learning_rate': result.x[1],\n",
    "        'max_depth': int(result.x[2]),\n",
    "        'feature_fraction': result.x[3],\n",
    "        'bagging_fraction': result.x[4],\n",
    "        'bagging_freq': int(result.x[5]),\n",
    "        'min_data_in_leaf': int(result.x[6])\n",
    "    }\n",
    "\n",
    "    param = dict(best_params,**FIXED_PARAMS)\n",
    "\n",
    "    lgbtrain = lgb.Dataset(data=X_train_temp, label=Y_train_temp, feature_name=cols_no_fam)\n",
    "    lgbval = lgb.Dataset(data=X_val_temp, label=Y_val_temp, reference=lgbtrain, feature_name=cols_no_fam)\n",
    "    model = lgb.train(params=param,\n",
    "                    train_set=lgbtrain,\n",
    "                    valid_sets=[lgbtrain, lgbval],\n",
    "                    num_boost_round=FIXED_PARAMS['num_boost_round'],\n",
    "                    early_stopping_rounds=FIXED_PARAMS['early_stopping_rounds'],\n",
    "                    feval=rmsle_lgbm,\n",
    "                    verbose_eval=50)\n",
    "    save_model(DECISIONTREE_PATH,model,f'lgbm_valid_{fam}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(DECISIONTREE_PATH,model,'lgbm_valid.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lgb_importances(model,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model on full train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_PARAMS = {'num_leaves': 200, 'learning_rate': 0.5, 'max_depth': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 10, 'min_data_in_leaf': 23}\n",
    "\n",
    "FIXED_PARAMS={'objective': 'regression',\n",
    "              'metric': 'custom',\n",
    "              'boosting':'gbdt',\n",
    "              'min_gain_to_split':0.01,\n",
    "              'num_boost_round':1000}\n",
    "param = dict(SEARCH_PARAMS,**FIXED_PARAMS)\n",
    "cols_no_fam = [col for col in df_feats.columns if col not in ['date', 'id', \"sales\", \"day\",'target','family']]\n",
    "for fam in df_feats['family'].unique():\n",
    "    temp=df_feats[df_feats['family']==fam]\n",
    "    Y_train_temp = temp['sales']\n",
    "    X_train_temp = temp[cols_no_fam]\n",
    "    model=load_model(DECISIONTREE_PATH,f'lgbm_valid_{fam}.pkl')\n",
    "    param= model.params\n",
    "    try:\n",
    "        param.pop('early_stopping_round')\n",
    "    except:\n",
    "        param=param\n",
    "    lgbtrain = lgb.Dataset(data=X_train_temp, label=Y_train_temp, feature_name=cols_no_fam)\n",
    "    final_model = lgb.train(params=param,\n",
    "                  train_set=lgbtrain,\n",
    "                  num_boost_round=model.best_iteration,\n",
    "                  feval=rmsle_lgbm)\n",
    "    save_model(DECISIONTREE_PATH,model,f'lgbm_all_{fam}.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.DataFrame()\n",
    "cols_no_fam = [col for col in df_feats.columns if col not in ['date', 'id', \"sales\", \"day\",'target','family']]\n",
    "for fam in df_feats['family'].unique():\n",
    "    print(fam)\n",
    "    for sto in df_feats.store_nbr.unique():\n",
    "        temp=df_test_feats[(df_test_feats['family']==fam) & (df_test_feats['store_nbr']==sto)]\n",
    "        temp_test = test[(test['family']==df_le[df_le['family_le']==fam].family.item()) & (test['store_nbr']==sto)]\n",
    "        temp_test = temp_test.loc[temp_test.sales.isna()]\n",
    "        X_test = temp[cols_no_fam]\n",
    "        train_temp=df_feats[(df_feats['family']==fam) & (df_feats['store_nbr']==sto)]\n",
    "    \n",
    "        final_model=load_model(DECISIONTREE_PATH,f'lgbm_all_{fam}.pkl')\n",
    "        test_preds = final_model.predict(X_test, num_iteration=final_model.best_iteration)\n",
    "        # Zeroes the prediction\n",
    "        for i in range(len(test_preds)):\n",
    "            test_preds[i]=max(0,test_preds[i])\n",
    "            # If last 21 days are 0s then 0\n",
    "            if train_temp.loc[-21:].sales.sum()==0:\n",
    "                try:\n",
    "                    test_preds.loc[i]=0\n",
    "                except:\n",
    "                    test_preds[i]=0\n",
    "        submission_df = temp_test.loc[:, ['id', 'sales']]\n",
    "        submission_df['sales'] = test_preds\n",
    "        submission_df['id'] = submission_df.id.astype(int)        \n",
    "        submission=submission.append(submission_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort Values\n",
    "submission=submission.sort_values('id')\n",
    "\n",
    "#Saving the submission file !!!Update the name of the file!!!\n",
    "submission.to_csv(SUBMISSION_PATH/'submission_lgbm_11.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
